{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization: Training Neural Networks\n",
    "\n",
    "Optimization is the process of finding the best parameters (weights and biases) for our neural network. We use gradients computed by backpropagation to iteratively improve these parameters.\n",
    "\n",
    "## What You'll Learn:\n",
    "1. **Gradient Descent** - The fundamental algorithm\n",
    "2. **Learning Rate** - The most important hyperparameter\n",
    "3. **Momentum** - Accelerating training\n",
    "4. **Adam** - The most popular optimizer\n",
    "5. **Learning Rate Schedules** - Adapting over time\n",
    "6. **Regularization** - Preventing overfitting\n",
    "\n",
    "**Goal:** Minimize the loss function $L(\\theta)$ where $\\theta$ represents all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gradient Descent: The Foundation\n",
    "\n",
    "**Gradient Descent** is the fundamental optimization algorithm. It updates parameters in the direction that decreases the loss.\n",
    "\n",
    "### Algorithm:\n",
    "Repeat until convergence:\n",
    "1. Compute gradient: $g = \\nabla_\\theta L(\\theta)$\n",
    "2. Update parameters: $\\theta \\leftarrow \\theta - \\alpha g$\n",
    "\n",
    "where $\\alpha$ is the **learning rate**.\n",
    "\n",
    "### Intuition:\n",
    "- The gradient points **uphill** (direction of steepest increase)\n",
    "- We go in the **opposite direction** to decrease loss\n",
    "- Learning rate controls step size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Visualizing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple 1D example: minimize f(x) = x^2\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def df_dx(x):\n",
    "    return 2*x\n",
    "\n",
    "# Gradient descent\n",
    "x = 10.0  # starting point\n",
    "learning_rate = 0.1\n",
    "history = [x]\n",
    "\n",
    "for _ in range(20):\n",
    "    gradient = df_dx(x)\n",
    "    x = x - learning_rate * gradient\n",
    "    history.append(x)\n",
    "\n",
    "# Visualize\n",
    "x_vals = np.linspace(-10, 10, 200)\n",
    "y_vals = f(x_vals)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_vals, y_vals, 'b-', linewidth=2, label='f(x) = x²')\n",
    "plt.plot(history, [f(x) for x in history], 'ro-', markersize=8, label='Gradient descent path')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Gradient Descent on f(x) = x²')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([f(x) for x in history], 'ro-', markersize=6)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Loss Decreasing Over Time')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Starting point: x = {history[0]:.4f}, f(x) = {f(history[0]):.4f}\")\n",
    "print(f\"Final point: x = {history[-1]:.4f}, f(x) = {f(history[-1]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Gradient Descent in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D example: minimize f(x, y) = x^2 + y^2\n",
    "def f_2d(x, y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "def gradient_2d(x, y):\n",
    "    return np.array([2*x, 2*y])\n",
    "\n",
    "# Gradient descent\n",
    "pos = np.array([8.0, 6.0])  # starting point\n",
    "learning_rate = 0.1\n",
    "history = [pos.copy()]\n",
    "\n",
    "for _ in range(50):\n",
    "    grad = gradient_2d(pos[0], pos[1])\n",
    "    pos = pos - learning_rate * grad\n",
    "    history.append(pos.copy())\n",
    "\n",
    "history = np.array(history)\n",
    "\n",
    "# Visualize\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y = np.linspace(-10, 10, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f_2d(X, Y)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "contour = plt.contour(X, Y, Z, levels=20)\n",
    "plt.clabel(contour, inline=True, fontsize=8)\n",
    "plt.plot(history[:, 0], history[:, 1], 'ro-', markersize=6, linewidth=2, label='GD path')\n",
    "plt.plot(history[0, 0], history[0, 1], 'gs', markersize=12, label='Start')\n",
    "plt.plot(history[-1, 0], history[-1, 1], 'r*', markersize=15, label='End')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Gradient Descent Path')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "losses = [f_2d(h[0], h[1]) for h in history]\n",
    "plt.plot(losses, 'b-', linewidth=2)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Over Time')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Learning Rate: The Most Important Hyperparameter\n",
    "\n",
    "The learning rate $\\alpha$ controls how big a step we take.\n",
    "\n",
    "### Issues:\n",
    "- **Too small**: Slow convergence, might not reach minimum\n",
    "- **Too large**: Oscillation, divergence, overshooting\n",
    "- **Just right**: Fast, stable convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_1d(x0, learning_rate, num_steps=50):\n",
    "    \"\"\"Run gradient descent on f(x) = x^2\"\"\"\n",
    "    x = x0\n",
    "    history = [x]\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        grad = 2 * x\n",
    "        x = x - learning_rate * grad\n",
    "        history.append(x)\n",
    "        \n",
    "        # Stop if diverging\n",
    "        if abs(x) > 1000:\n",
    "            break\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Try different learning rates\n",
    "x0 = 10.0\n",
    "learning_rates = [0.01, 0.1, 0.5, 0.9, 1.1]\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "for i, lr in enumerate(learning_rates, 1):\n",
    "    history = gradient_descent_1d(x0, lr, num_steps=20)\n",
    "    \n",
    "    plt.subplot(1, len(learning_rates), i)\n",
    "    plt.plot([f(x) for x in history], 'o-', markersize=4)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.title(f'LR = {lr}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(history) > 1 and abs(history[-1]) > 100:\n",
    "        plt.ylim(0, min(1000, max([f(x) for x in history[:10]])))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"- LR=0.01: Very slow convergence\")\n",
    "print(\"- LR=0.1: Good convergence\")\n",
    "print(\"- LR=0.5: Fast but some oscillation\")\n",
    "print(\"- LR=0.9: Large oscillations\")\n",
    "print(\"- LR=1.1: Diverges! (explodes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Types of Gradient Descent\n",
    "\n",
    "### 3.1 Batch Gradient Descent\n",
    "- Uses **entire dataset** to compute gradient\n",
    "- Accurate but slow for large datasets\n",
    "- Formula: $\\theta \\leftarrow \\theta - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} \\nabla L^{(i)}$\n",
    "\n",
    "### 3.2 Stochastic Gradient Descent (SGD)\n",
    "- Uses **one sample** at a time\n",
    "- Fast but noisy updates\n",
    "- Formula: $\\theta \\leftarrow \\theta - \\alpha \\nabla L^{(i)}$\n",
    "\n",
    "### 3.3 Mini-Batch Gradient Descent (Most Common)\n",
    "- Uses **small batches** (e.g., 32, 64, 128 samples)\n",
    "- Balance of speed and stability\n",
    "- Formula: $\\theta \\leftarrow \\theta - \\alpha \\frac{1}{b} \\sum_{i \\in \\text{batch}} \\nabla L^{(i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Momentum: Accelerating Gradient Descent\n",
    "\n",
    "**Problem with vanilla GD:** Can be slow in ravines (steep in one direction, shallow in another)\n",
    "\n",
    "**Momentum** adds a \"velocity\" term that accumulates gradients:\n",
    "\n",
    "$v_t = \\beta v_{t-1} + (1-\\beta) g_t$\n",
    "\n",
    "$\\theta_{t+1} = \\theta_t - \\alpha v_t$\n",
    "\n",
    "where:\n",
    "- $v_t$ is the velocity\n",
    "- $\\beta$ is the momentum coefficient (typically 0.9)\n",
    "- $g_t$ is the gradient\n",
    "\n",
    "**Benefits:**\n",
    "- Accelerates in consistent directions\n",
    "- Dampens oscillations\n",
    "- Helps escape local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare vanilla GD vs. Momentum\n",
    "# Optimize: f(x, y) = x^2 + 10*y^2 (ravine along x-axis)\n",
    "\n",
    "def f_ravine(x, y):\n",
    "    return x**2 + 10*y**2\n",
    "\n",
    "def grad_ravine(x, y):\n",
    "    return np.array([2*x, 20*y])\n",
    "\n",
    "# Vanilla GD\n",
    "def vanilla_gd(x0, y0, lr, num_steps):\n",
    "    pos = np.array([x0, y0])\n",
    "    history = [pos.copy()]\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        grad = grad_ravine(pos[0], pos[1])\n",
    "        pos = pos - lr * grad\n",
    "        history.append(pos.copy())\n",
    "    \n",
    "    return np.array(history)\n",
    "\n",
    "# Momentum\n",
    "def momentum_gd(x0, y0, lr, beta, num_steps):\n",
    "    pos = np.array([x0, y0])\n",
    "    velocity = np.zeros(2)\n",
    "    history = [pos.copy()]\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        grad = grad_ravine(pos[0], pos[1])\n",
    "        velocity = beta * velocity + (1 - beta) * grad\n",
    "        pos = pos - lr * velocity\n",
    "        history.append(pos.copy())\n",
    "    \n",
    "    return np.array(history)\n",
    "\n",
    "# Run both\n",
    "x0, y0 = 5.0, 2.0\n",
    "lr = 0.1\n",
    "num_steps = 50\n",
    "\n",
    "history_vanilla = vanilla_gd(x0, y0, lr, num_steps)\n",
    "history_momentum = momentum_gd(x0, y0, lr, beta=0.9, num_steps)\n",
    "\n",
    "# Visualize\n",
    "x = np.linspace(-6, 6, 100)\n",
    "y = np.linspace(-3, 3, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f_ravine(X, Y)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Contour plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.contour(X, Y, Z, levels=30, alpha=0.6)\n",
    "plt.plot(history_vanilla[:, 0], history_vanilla[:, 1], 'ro-', \n",
    "         markersize=4, linewidth=2, alpha=0.7, label='Vanilla GD')\n",
    "plt.plot(history_momentum[:, 0], history_momentum[:, 1], 'bs-', \n",
    "         markersize=4, linewidth=2, alpha=0.7, label='Momentum')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Optimization Paths (Ravine Function)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss curves\n",
    "plt.subplot(1, 2, 2)\n",
    "losses_vanilla = [f_ravine(h[0], h[1]) for h in history_vanilla]\n",
    "losses_momentum = [f_ravine(h[0], h[1]) for h in history_momentum]\n",
    "plt.plot(losses_vanilla, 'ro-', linewidth=2, alpha=0.7, label='Vanilla GD')\n",
    "plt.plot(losses_momentum, 'bs-', linewidth=2, alpha=0.7, label='Momentum')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Convergence Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final loss (Vanilla GD): {losses_vanilla[-1]:.6f}\")\n",
    "print(f\"Final loss (Momentum): {losses_momentum[-1]:.6f}\")\n",
    "print(\"\\nMomentum converges faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adam: The Most Popular Optimizer\n",
    "\n",
    "**Adam** (Adaptive Moment Estimation) combines:\n",
    "- Momentum (first moment)\n",
    "- Adaptive learning rates (second moment)\n",
    "\n",
    "### Algorithm:\n",
    "\n",
    "Initialize:\n",
    "- $m_0 = 0$ (first moment)\n",
    "- $v_0 = 0$ (second moment)\n",
    "\n",
    "For each iteration $t$:\n",
    "1. Compute gradient: $g_t$\n",
    "2. Update first moment: $m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t$\n",
    "3. Update second moment: $v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2$\n",
    "4. Bias correction: $\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t}$, $\\hat{v}_t = \\frac{v_t}{1-\\beta_2^t}$\n",
    "5. Update parameters: $\\theta_t = \\theta_{t-1} - \\alpha \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$\n",
    "\n",
    "**Default hyperparameters:**\n",
    "- $\\beta_1 = 0.9$ (momentum)\n",
    "- $\\beta_2 = 0.999$ (variance)\n",
    "- $\\epsilon = 10^{-8}$ (numerical stability)\n",
    "- $\\alpha = 0.001$ (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    \"\"\"\n",
    "    Adam optimizer implementation from scratch\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = None  # first moment\n",
    "        self.v = None  # second moment\n",
    "        self.t = 0     # time step\n",
    "    \n",
    "    def step(self, params, grads):\n",
    "        \"\"\"\n",
    "        Update parameters using Adam\n",
    "        \n",
    "        Args:\n",
    "            params: dict of parameters\n",
    "            grads: dict of gradients\n",
    "        \"\"\"\n",
    "        if self.m is None:\n",
    "            # Initialize moment estimates\n",
    "            self.m = {k: np.zeros_like(v) for k, v in params.items()}\n",
    "            self.v = {k: np.zeros_like(v) for k, v in params.items()}\n",
    "        \n",
    "        self.t += 1\n",
    "        \n",
    "        for key in params.keys():\n",
    "            # Update biased first moment\n",
    "            self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n",
    "            \n",
    "            # Update biased second moment\n",
    "            self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * (grads[key]**2)\n",
    "            \n",
    "            # Bias correction\n",
    "            m_hat = self.m[key] / (1 - self.beta1**self.t)\n",
    "            v_hat = self.v[key] / (1 - self.beta2**self.t)\n",
    "            \n",
    "            # Update parameters\n",
    "            params[key] -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "\n",
    "print(\"Adam optimizer implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparing Optimizers on a Real Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "X, y = make_moons(n_samples=1000, noise=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Define model\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Train with different optimizers\n",
    "def train_model(optimizer_name, lr=0.01, num_epochs=100):\n",
    "    model = SimpleNet()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Create optimizer\n",
    "    if optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'Momentum':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    elif optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward\n",
    "        outputs = model(X_train_t)\n",
    "        loss = criterion(outputs, y_train_t)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            accuracy = (predicted == y_train_t).float().mean().item()\n",
    "            accuracies.append(accuracy)\n",
    "    \n",
    "    return losses, accuracies\n",
    "\n",
    "# Compare optimizers\n",
    "optimizers = ['SGD', 'Momentum', 'Adam', 'RMSprop']\n",
    "results = {}\n",
    "\n",
    "for opt in optimizers:\n",
    "    print(f\"Training with {opt}...\")\n",
    "    losses, accs = train_model(opt, lr=0.01, num_epochs=200)\n",
    "    results[opt] = {'losses': losses, 'accuracies': accs}\n",
    "\n",
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for opt in optimizers:\n",
    "    ax1.plot(results[opt]['losses'], label=opt, linewidth=2)\n",
    "    ax2.plot(results[opt]['accuracies'], label=opt, linewidth=2)\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training Accuracy Comparison')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Adam typically converges fastest\")\n",
    "print(\"- Momentum helps vanilla SGD significantly\")\n",
    "print(\"- RMSprop also adapts learning rates per parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Learning Rate Schedules\n",
    "\n",
    "Often beneficial to **decrease learning rate** over time:\n",
    "- Start with large steps (explore quickly)\n",
    "- End with small steps (fine-tune)\n",
    "\n",
    "### Common Schedules:\n",
    "\n",
    "1. **Step Decay**: Reduce by factor every N epochs\n",
    "   - $\\alpha_t = \\alpha_0 \\cdot \\gamma^{\\lfloor t/N \\rfloor}$\n",
    "\n",
    "2. **Exponential Decay**: Smooth exponential decrease\n",
    "   - $\\alpha_t = \\alpha_0 \\cdot e^{-kt}$\n",
    "\n",
    "3. **Cosine Annealing**: Follows cosine curve\n",
    "   - $\\alpha_t = \\alpha_{min} + \\frac{1}{2}(\\alpha_{max} - \\alpha_{min})(1 + \\cos(\\frac{t\\pi}{T}))$\n",
    "\n",
    "4. **Reduce on Plateau**: Reduce when validation loss stops improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize different schedules\n",
    "num_epochs = 100\n",
    "lr_0 = 0.1\n",
    "\n",
    "# Step decay\n",
    "step_lr = [lr_0 * (0.5 ** (t // 20)) for t in range(num_epochs)]\n",
    "\n",
    "# Exponential decay\n",
    "exp_lr = [lr_0 * np.exp(-0.05 * t) for t in range(num_epochs)]\n",
    "\n",
    "# Cosine annealing\n",
    "cosine_lr = [0.001 + 0.5 * (lr_0 - 0.001) * (1 + np.cos(np.pi * t / num_epochs)) \n",
    "             for t in range(num_epochs)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.plot(step_lr, label='Step Decay', linewidth=2)\n",
    "plt.plot(exp_lr, label='Exponential Decay', linewidth=2)\n",
    "plt.plot(cosine_lr, label='Cosine Annealing', linewidth=2)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedules')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using PyTorch schedulers\n",
    "model = SimpleNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Cosine annealing scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0.001)\n",
    "\n",
    "# Track learning rate\n",
    "lrs = []\n",
    "for epoch in range(100):\n",
    "    # Training step would go here\n",
    "    lrs.append(optimizer.param_groups[0]['lr'])\n",
    "    scheduler.step()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(lrs, linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('PyTorch CosineAnnealingLR Scheduler')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Regularization: Preventing Overfitting\n",
    "\n",
    "### 8.1 L2 Regularization (Weight Decay)\n",
    "\n",
    "Add penalty for large weights:\n",
    "\n",
    "$L_{total} = L_{data} + \\frac{\\lambda}{2} \\sum_{i} w_i^2$\n",
    "\n",
    "Gradient becomes: $\\nabla L = \\nabla L_{data} + \\lambda w$\n",
    "\n",
    "**Effect**: Prevents weights from becoming too large, improves generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with and without weight decay\n",
    "def train_with_regularization(weight_decay=0.0, num_epochs=200):\n",
    "    model = SimpleNet()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=weight_decay)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        outputs = model(X_train_t)\n",
    "        loss = criterion(outputs, y_train_t)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        # Test\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_t)\n",
    "            test_loss = criterion(test_outputs, y_test_t)\n",
    "            test_losses.append(test_loss.item())\n",
    "    \n",
    "    return train_losses, test_losses\n",
    "\n",
    "# Train with different weight decay values\n",
    "wd_values = [0.0, 0.001, 0.01]\n",
    "results_wd = {}\n",
    "\n",
    "for wd in wd_values:\n",
    "    print(f\"Training with weight_decay={wd}...\")\n",
    "    train_loss, test_loss = train_with_regularization(weight_decay=wd)\n",
    "    results_wd[wd] = {'train': train_loss, 'test': test_loss}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for wd in wd_values:\n",
    "    plt.plot(results_wd[wd]['train'], label=f'WD={wd}', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss vs Weight Decay')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for wd in wd_values:\n",
    "    plt.plot(results_wd[wd]['test'], label=f'WD={wd}', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.title('Test Loss vs Weight Decay')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Moderate weight decay often improves test performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Optimization Concepts:\n",
    "\n",
    "1. **Gradient Descent**\n",
    "   - Update: $\\theta \\leftarrow \\theta - \\alpha \\nabla L$\n",
    "   - Goes \"downhill\" to minimize loss\n",
    "   - Three variants: Batch, Stochastic, Mini-batch\n",
    "\n",
    "2. **Learning Rate**\n",
    "   - Most important hyperparameter\n",
    "   - Too small = slow, too large = unstable\n",
    "   - Typical starting values: 0.001 - 0.01\n",
    "\n",
    "3. **Momentum**\n",
    "   - Accelerates in consistent directions\n",
    "   - Dampens oscillations\n",
    "   - Default: $\\beta = 0.9$\n",
    "\n",
    "4. **Adam** (Recommended Default)\n",
    "   - Combines momentum + adaptive learning rates\n",
    "   - Works well out of the box\n",
    "   - Defaults: $\\alpha=0.001, \\beta_1=0.9, \\beta_2=0.999$\n",
    "\n",
    "5. **Learning Rate Schedules**\n",
    "   - Reduce LR over time for fine-tuning\n",
    "   - Common: Step decay, cosine annealing\n",
    "\n",
    "6. **Regularization**\n",
    "   - L2 (weight decay): Prevents large weights\n",
    "   - Improves generalization\n",
    "\n",
    "### Practical Recommendations:\n",
    "\n",
    "**For most problems:**\n",
    "- Start with Adam optimizer\n",
    "- Learning rate: 0.001 (or tune)\n",
    "- Mini-batch size: 32-128\n",
    "- Add weight decay: 0.001-0.01\n",
    "\n",
    "**If Adam doesn't work:**\n",
    "- Try SGD with momentum (0.9)\n",
    "- Use learning rate scheduler\n",
    "- Tune learning rate carefully\n",
    "\n",
    "### Next Steps:\n",
    "In the next notebook, we'll explore **attention mechanisms** - the foundation of modern transformers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Implement RMSprop from scratch\n",
    "# RMSprop: v_t = beta * v_{t-1} + (1-beta) * g_t^2\n",
    "#          theta_t = theta_{t-1} - alpha * g_t / sqrt(v_t + epsilon)\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Find the optimal learning rate\n",
    "# Use learning rate finder: train with exponentially increasing LRs\n",
    "# Plot loss vs LR to find the sweet spot\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Implement early stopping\n",
    "# Stop training when validation loss stops improving for N epochs\n",
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
